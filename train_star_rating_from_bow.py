import os
import joblib
from sklearn.feature_extraction import DictVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.linear_model import SGDClassifier
from xgboost import XGBClassifier
import numpy as np
from collections import defaultdict
import random

INPUT_BASE = "datasets/sorted_data"
INPUT_FILENAME = "all.bow.review"
MAX_SAMPLES = None  # âœ… æœ€å¤šä½¿ç”¨å¤šå°‘ç­†è³‡æ–™ï¼Œè¨­ç‚º None å‰‡ä½¿ç”¨å…¨éƒ¨

def load_bow_review_file(filepath):
    X, y = [], []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split()
            bow = {}
            label = None
            for item in parts:
                if item.startswith("#label#"):
                    label = float(item.split(":")[1])
                else:
                    word, count = item.rsplit(":", 1)
                    bow[word] = int(count)
            if label is not None:
                X.append(bow)
                y.append(label)
    return X, y

# 1. è¼‰å…¥æ‰€æœ‰åˆ†é¡çš„ .bow.review
def load_all_domains(base_path):
    all_X, all_y = [], []
    for domain in os.listdir(base_path):
        bow_path = os.path.join(base_path, domain, INPUT_FILENAME)
        if os.path.isfile(bow_path):
            print(f"ğŸ“‚ è®€å– {bow_path}...")
            X, y = load_bow_review_file(bow_path)
            all_X.extend(X)
            all_y.extend(y)
            print(f"  âœ… ç­†æ•¸ï¼š{len(X)}")
    return all_X, all_y

def balance_dataset(X_raw, y):
    grouped = defaultdict(list)
    for x, label in zip(X_raw, y):
        grouped[label].append(x)

    min_class_size = min(len(g) for g in grouped.values())  # ä¾‹ï¼šæœ€å°‘çš„æ˜Ÿç­‰æœ‰ 16,347 ç­†

    X_balanced, y_balanced = [], []
    for label, samples in grouped.items():
        sampled = random.sample(samples, min_class_size)
        X_balanced.extend(sampled)
        y_balanced.extend([label] * min_class_size)

    print(f"âš–ï¸ å¹³è¡¡å¾Œæ¯é¡åˆ¥ç­†æ•¸ï¼š{min_class_size}ï¼Œç¸½æ•¸ï¼š{len(X_balanced)}")
    return X_balanced, y_balanced

if __name__ == "__main__":
    # è®€å–è³‡æ–™
    X_raw, y = load_all_domains(INPUT_BASE)
    X_raw, y = balance_dataset(X_raw, y)

    unique_classes = sorted(set(y))  # [1.0, 2.0, 4.0, 5.0]
    class_map = {c: i for i, c in enumerate(unique_classes)}
    class_inv_map = {i: c for c, i in class_map.items()}
    print("ğŸ“˜ é¡åˆ¥å°æ‡‰ï¼š", class_map)

    # å„²å­˜é‚„åŸå°æ‡‰è¡¨ï¼Œä¾›é æ¸¬ç”¨
    joblib.dump(class_inv_map, "class_inv_map.pkl")
    # è½‰æ›æˆé€£çºŒæ•´æ•¸æ¨™ç±¤
    y_mapped = np.array([class_map[label] for label in y])

    # âœ… é™åˆ¶æ¨£æœ¬æ•¸é‡ï¼ˆåŠ é€Ÿè¨“ç·´ï¼‰
    if MAX_SAMPLES and len(X_raw) > MAX_SAMPLES:
        X_raw = X_raw[:MAX_SAMPLES]
        y = y[:MAX_SAMPLES]
        print(f"âš¡ ä½¿ç”¨å‰ {MAX_SAMPLES} ç­†è³‡æ–™è¨“ç·´")

    # å‘é‡åŒ–
    print("ğŸ”§ å‘é‡åŒ–ä¸­...")
    vectorizer = DictVectorizer()
    X = vectorizer.fit_transform(X_raw)

    # åˆ‡åˆ†è¨“ç·´/æ¸¬è©¦é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y_mapped, test_size=0.2, random_state=42)

    # å»ºç«‹ä¸¦è¨“ç·´æ¨¡å‹
    print("ğŸ§  è¨“ç·´æ¨¡å‹ä¸­...")
    # model = LogisticRegression(solver="saga", max_iter=1000, class_weight="balanced", n_jobs=-1)
    # model = SGDClassifier(loss="log_loss", max_iter=1000, class_weight="balanced", n_jobs=-1, random_state=42)
    model = XGBClassifier(
        objective='multi:softmax',
        num_class=5,
        eval_metric='mlogloss',
        use_label_encoder=False,
        n_jobs=-1,
        random_state=42
    )
    model.fit(X_train, y_train)

    # é æ¸¬èˆ‡è©•ä¼°
    print("ğŸ“Š æ¨¡å‹è©•ä¼°çµæœï¼š")
    y_pred = model.predict(X_test)
    y_pred_real = [class_inv_map[int(p)] for p in y_pred]
    y_test_real = [class_inv_map[int(t)] for t in y_test]
    print(classification_report(y_test_real, y_pred_real, digits=3))

    # å„²å­˜æ¨¡å‹èˆ‡å‘é‡å™¨
    joblib.dump(model, "star_rating_model.pkl")
    joblib.dump(vectorizer, "star_rating_vectorizer.pkl")
    print("ğŸ’¾ æ¨¡å‹èˆ‡å‘é‡å™¨å·²å„²å­˜")